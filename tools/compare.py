#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import sys
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° sys.path ä»¥ä¾¿å¯¼å…¥ config_loader
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config_loader import load_cluster_config


def load(path: str) -> dict:
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)


def compare_cases(a: dict, b: dict) -> list:
    amap = {c['name']: c for c in a.get('cases', [])}
    bmap = {c['name']: c for c in b.get('cases', [])}
    names = sorted(set(amap.keys()) & set(bmap.keys()))
    out = []
    for n in names:
        ca = amap[n]; cb = bmap[n]
        def metric(baseline, current):
            delta = current - baseline
            pct = (delta / baseline * 100.0) if baseline not in (0, 0.0) else None
            return {'baseline': baseline, 'current': current, 'delta': delta, 'delta_pct': pct}
        item = {'name': n}
        item['read_iops'] = metric(ca['read']['iops'], cb['read']['iops'])
        item['write_iops'] = metric(ca['write']['iops'], cb['write']['iops'])
        item['read_bw'] = metric(ca['read']['bw_MBps'], cb['read']['bw_MBps'])
        item['write_bw'] = metric(ca['write']['bw_MBps'], cb['write']['bw_MBps'])
        # å»¶è¿Ÿè¶Šå°è¶Šå¥½ï¼šé™„åŠ è¶‹åŠ¿
        rl = metric(ca['read']['lat_us'], cb['read']['lat_us'])
        wl = metric(ca['write']['lat_us'], cb['write']['lat_us'])
        rl['trend'] = 'improved' if rl['delta'] < 0 else ('declined' if rl['delta'] > 0 else 'flat')
        wl['trend'] = 'improved' if wl['delta'] < 0 else ('declined' if wl['delta'] > 0 else 'flat')
        item['read_lat_us'] = rl
        item['write_lat_us'] = wl
        out.append(item)
    return out


def _to_float(s: str) -> float:
    try:
        return float(s.strip())
    except Exception:
        return 0.0


def parse_md_cases(md_path: str) -> dict:
    if not os.path.isfile(md_path):
        return {'cases': []}
    with open(md_path, 'r', encoding='utf-8', errors='ignore') as f:
        lines = f.read().splitlines()
    cases = []
    header_idx = -1
    for i, l in enumerate(lines):
        if l.strip().startswith('|') and ('åç§°' in l or 'è¯»å†™æ¨¡å¼' in l):
            header_idx = i
            break
    if header_idx == -1:
        return {'cases': []}
    header_cells = [c.strip() for c in lines[header_idx].split('|')]
    col_map = {name: idx for idx, name in enumerate(header_cells) if name}
    sep_idx = header_idx + 1
    for j in range(sep_idx + 1, len(lines)):
        row = lines[j].strip()
        if not row.startswith('|'):
            break
        cells = [c.strip() for c in row.split('|')]
        if len(cells) < len(header_cells):
            continue
        if 'åç§°' in col_map:
            name = cells[col_map['åç§°']]
            riops = _to_float(cells[col_map.get('è¯»IOPS','') or 0])
            wiops = _to_float(cells[col_map.get('å†™IOPS','') or 0])
            rmbps = _to_float(cells[col_map.get('è¯»MB/s','') or 0])
            wmbps = _to_float(cells[col_map.get('å†™MB/s','') or 0])
            rlat = _to_float(cells[col_map.get('è¯»å»¶è¿Ÿ(Î¼s)','') or 0])
            wlat = _to_float(cells[col_map.get('å†™å»¶è¿Ÿ(Î¼s)','') or 0])
        else:
            mode = cells[col_map.get('è¯»å†™æ¨¡å¼', 0)]
            qd = cells[col_map.get('é˜Ÿåˆ—æ·±åº¦', 0)]
            nj = cells[col_map.get('å¹¶å‘æ•°', 0)]
            name = f"{mode} QD{qd} J{nj}"
            riops = _to_float(cells[col_map.get('è¯»å–IOPS','') or 0])
            wiops = _to_float(cells[col_map.get('å†™å…¥IOPS','') or 0])
            rmbps = _to_float(cells[col_map.get('è¯»å–å¸¦å®½(MB/s)','') or 0])
            wmbps = _to_float(cells[col_map.get('å†™å…¥å¸¦å®½(MB/s)','') or 0])
            rlat = _to_float(cells[col_map.get('è¯»å–å»¶è¿Ÿ(Î¼s)','') or 0])
            wlat = _to_float(cells[col_map.get('å†™å…¥å»¶è¿Ÿ(Î¼s)','') or 0])
        cases.append({
            'name': name,
            'read': {'iops': riops, 'bw_MBps': rmbps, 'lat_us': rlat},
            'write': {'iops': wiops, 'bw_MBps': wmbps, 'lat_us': wlat},
        })
    return {'cases': cases}


def auto_pick(base_dir: str) -> tuple[str, str]:
    candidates = []
    for d in os.listdir(base_dir):
        if d[:8].isdigit() and '-' in d:
            agg_path = os.path.join(base_dir, d, 'aggregate.json')
            if os.path.isfile(agg_path):
                candidates.append(d)
    stamps = sorted(candidates)
    if len(stamps) < 2:
        raise RuntimeError('ä¸è¶³ä¸¤ä»½èšåˆæŠ¥å‘Šç”¨äºè‡ªåŠ¨å¯¹æ¯”')
    return stamps[-2], stamps[-1]


def write_md(out_path: str, title: str, meta: dict, items: list):
    lines = []
    lines.append(f"# {title}\n")
    lines.append(f"ç”Ÿæˆæ—¶é—´: {__import__('time').strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append("## å…ƒä¿¡æ¯\n")
    for k, v in meta.items():
        lines.append(f"- {k}: {v}\n")
    # æ‘˜è¦ç»Ÿè®¡
    improved = {'read_iops':0,'write_iops':0,'read_bw':0,'write_bw':0,'read_lat_us':0,'write_lat_us':0}
    declined = {'read_iops':0,'write_iops':0,'read_bw':0,'write_bw':0,'read_lat_us':0,'write_lat_us':0}
    for it in items:
        ri = it['read_iops']; wi = it['write_iops']; rb = it['read_bw']; wb = it['write_bw']; rl = it['read_lat_us']; wl = it['write_lat_us']
        if ri['delta']>0: improved['read_iops']+=1
        elif ri['delta']<0: declined['read_iops']+=1
        if wi['delta']>0: improved['write_iops']+=1
        elif wi['delta']<0: declined['write_iops']+=1
        if rb['delta']>0: improved['read_bw']+=1
        elif rb['delta']<0: declined['read_bw']+=1
        if wb['delta']>0: improved['write_bw']+=1
        elif wb['delta']<0: declined['write_bw']+=1
        if rl['delta']<0: improved['read_lat_us']+=1
        elif rl['delta']>0: declined['read_lat_us']+=1
        if wl['delta']<0: improved['write_lat_us']+=1
        elif wl['delta']>0: declined['write_lat_us']+=1
    lines.append("\n## æ‘˜è¦\n\n")
    lines.append(
        f"- è¯»IOPS: ğŸ“ˆ{improved['read_iops']} / ğŸ“‰{declined['read_iops']}\n"
        f"- å†™IOPS: ğŸ“ˆ{improved['write_iops']} / ğŸ“‰{declined['write_iops']}\n"
        f"- è¯»MB/s: ğŸ“ˆ{improved['read_bw']} / ğŸ“‰{declined['read_bw']}\n"
        f"- å†™MB/s: ğŸ“ˆ{improved['write_bw']} / ğŸ“‰{declined['write_bw']}\n"
        f"- è¯»å»¶è¿Ÿ(Î¼s): âœ…æ”¹å–„ {improved['read_lat_us']} / âŒå˜å·® {declined['read_lat_us']}\n"
        f"- å†™å»¶è¿Ÿ(Î¼s): âœ…æ”¹å–„ {improved['write_lat_us']} / âŒå˜å·® {declined['write_lat_us']}\n"
    )
    # Topå˜åŒ–
    def top_list(metric_key: str, asc: bool, limit: int = 5):
        arr = []
        for it in items:
            m = it[metric_key]['delta']
            arr.append((it['name'], m))
        arr.sort(key=lambda x: x[1], reverse=not asc)
        return arr[:limit]
    tops = {
        'è¯»IOPSâ†‘': top_list('read_iops', asc=False),
        'è¯»IOPSâ†“': top_list('read_iops', asc=True),
        'å†™IOPSâ†‘': top_list('write_iops', asc=False),
        'å†™IOPSâ†“': top_list('write_iops', asc=True),
        'è¯»MB/sâ†‘': top_list('read_bw', asc=False),
        'è¯»MB/sâ†“': top_list('read_bw', asc=True),
        'å†™MB/sâ†‘': top_list('write_bw', asc=False),
        'å†™MB/sâ†“': top_list('write_bw', asc=True),
    }
    lines.append("\n## Topå˜åŒ–\n\n")
    for k, arr in tops.items():
        lines.append(f"- {k}: ")
        if not arr:
            lines.append("æ— \n")
        else:
            lines.append(", ".join([f"{name} ({delta:+.2f})" for name, delta in arr]) + "\n")

    lines.append("\n## æŒ‡æ ‡å˜åŒ–\n\n")
    lines.append("| åç§° | è¯»IOPSÎ” | è¯»IOPS% | å†™IOPSÎ” | å†™IOPS% | è¯»MB/sÎ” | è¯»MB/s% | å†™MB/sÎ” | å†™MB/s% | è¯»å»¶è¿ŸÎ”(Î¼s) | å†™å»¶è¿ŸÎ”(Î¼s) | è¯»è¶‹åŠ¿ | å†™è¶‹åŠ¿ |\n")
    lines.append("|------|---------:|--------:|---------:|--------:|--------:|--------:|--------:|--------:|-----------:|-----------:|--------|--------|\n")
    for it in items:
        ri = it['read_iops']; wi = it['write_iops']; rb = it['read_bw']; wb = it['write_bw']; rl = it['read_lat_us']; wl = it['write_lat_us']
        def fmt_pct(x):
            return f"{x:.2f}%" if x is not None else "-"
        def emoj(t):
            return 'ğŸ“ˆ' if t=='improved' else ('ğŸ“‰' if t=='declined' else 'â–')
        lines.append(
            f"| {it['name']} | "
            f"{ri['delta']:.2f} | {fmt_pct(ri['delta_pct'])} | "
            f"{wi['delta']:.2f} | {fmt_pct(wi['delta_pct'])} | "
            f"{rb['delta']:.2f} | {fmt_pct(rb['delta_pct'])} | "
            f"{wb['delta']:.2f} | {fmt_pct(wb['delta_pct'])} | "
            f"{rl['delta']:.2f} | {wl['delta']:.2f} | "
            f"{emoj(rl.get('trend','flat'))} | {emoj(wl.get('trend','flat'))} |\n"
        )
    with open(out_path, 'w', encoding='utf-8') as f:
        f.writelines(lines)


def main():
    import argparse
    parser = argparse.ArgumentParser(description='å¯¹æ¯”ä¸¤ä»½æŠ¥å‘Š')
    parser.add_argument('--baseline')
    parser.add_argument('--current')
    parser.add_argument('--auto', action='store_true')
    parser.add_argument('--source', choices=['centralized', 'raw', 'auto'], default='auto')
    parser.add_argument('--host')
    parser.add_argument('--dirA')
    parser.add_argument('--dirB')
    args = parser.parse_args()

    # ä¼˜å…ˆæ”¯æŒæŒ‰ç›®å½•æŒ‡å®šï¼šç”¨æˆ·ç»™ä¸¤ä¸ªæ–‡ä»¶å¤¹å³å¯
    if args.dirA and args.dirB:
        a_dir = args.dirA
        b_dir = args.dirB
        a_agg = os.path.isfile(os.path.join(a_dir, 'aggregate.json'))
        b_agg = os.path.isfile(os.path.join(b_dir, 'aggregate.json'))
        def has_single(d: str) -> bool:
            if os.path.isfile(os.path.join(d, 'report.json')):
                return True
            # å­˜åœ¨ä¸»ç»¼åˆæŠ¥å‘ŠMD
            for f in os.listdir(d):
                if f.startswith('storage_performance_report_') and f.endswith('.md'):
                    return True
                if f.startswith('fio_detailed_report') and f.endswith('.md'):
                    return True
            return False
        a_single = has_single(a_dir)
        b_single = has_single(b_dir)
        if a_agg and b_agg:
            # èšåˆå¯¹æ¯”ï¼ˆ3pNvï¼‰
            A = load(os.path.join(a_dir, 'aggregate.json'))
            B = load(os.path.join(b_dir, 'aggregate.json'))
            pa = A.get('meta', {}).get('p'); pb = B.get('meta', {}).get('p')
            va = A.get('meta', {}).get('vm_count'); vb = B.get('meta', {}).get('vm_count')
            if pa != pb or va != vb:
                raise SystemExit(f'ä¸æ”¯æŒä¸åŒç±»å‹çš„å¯¹æ¯”: p={pa} vs {pb}, vm_count={va} vs {vb}')
            items = compare_cases(A, B)
            out_dir = os.path.join('test_data', 'reports', 'compare')
            os.makedirs(out_dir, exist_ok=True)
            bname = f"{os.path.basename(a_dir)}_vs_{os.path.basename(b_dir)}"
            out_json = os.path.join(out_dir, f'{bname}.json')
            with open(out_json, 'w', encoding='utf-8') as f:
                json.dump({'baseline': os.path.basename(a_dir), 'current': os.path.basename(b_dir), 'p': pa, 'vm_count': va, 'items': items}, f, ensure_ascii=False, indent=2)
            out_md = os.path.join(out_dir, f'{bname}.md')
            meta = {'ç±»å‹': 'é›†ä¸­èšåˆ(3pNv)', 'p': pa, 'vm_count': va, 'baseline': os.path.basename(a_dir), 'current': os.path.basename(b_dir)}
            write_md(out_md, 'èšåˆæŠ¥å‘Šå¯¹æ¯”', meta, items)
            print(out_json); print(out_md); return
        elif a_single and b_single:
            # å•æœºæŠ¥å‘Šå¯¹æ¯”ï¼ˆreports/<stamp>/report.json æˆ–è§£æMDï¼‰
            a_json = os.path.join(a_dir, 'report.json')
            b_json = os.path.join(b_dir, 'report.json')
            A = load(a_json) if os.path.isfile(a_json) else {'cases': []}
            B = load(b_json) if os.path.isfile(b_json) else {'cases': []}
            if not A.get('cases'):
                # å°è¯•è§£æ MDï¼ˆä¼˜å…ˆä¸»ç»¼åˆï¼Œå…¶æ¬¡è¯¦ç»†æŠ¥å‘Šï¼‰
                mdA = next((os.path.join(a_dir, f) for f in os.listdir(a_dir) if f.startswith('storage_performance_report_') and f.endswith('.md')), None)
                if not mdA:
                    mdA = next((os.path.join(a_dir, f) for f in os.listdir(a_dir) if f.startswith('fio_detailed_report') and f.endswith('.md')), None)
                A = parse_md_cases(mdA or '')
            if not B.get('cases'):
                mdB = next((os.path.join(b_dir, f) for f in os.listdir(b_dir) if f.startswith('storage_performance_report_') and f.endswith('.md')), None)
                if not mdB:
                    mdB = next((os.path.join(b_dir, f) for f in os.listdir(b_dir) if f.startswith('fio_detailed_report') and f.endswith('.md')), None)
                B = parse_md_cases(mdB or '')
            items = compare_cases({'cases': A.get('cases', [])}, {'cases': B.get('cases', [])})
            out_dir = os.path.join('test_data', 'reports', 'compare')
            os.makedirs(out_dir, exist_ok=True)
            bname = f"{os.path.basename(a_dir)}_vs_{os.path.basename(b_dir)}"
            out_json = os.path.join(out_dir, f'{bname}.json')
            with open(out_json, 'w', encoding='utf-8') as f:
                json.dump({'baseline': os.path.basename(a_dir), 'current': os.path.basename(b_dir), 'items': items}, f, ensure_ascii=False, indent=2)
            out_md = os.path.join(out_dir, f'{bname}.md')
            meta = {'ç±»å‹': 'å•æœºæŠ¥å‘Š', 'baseline': os.path.basename(a_dir), 'current': os.path.basename(b_dir)}
            write_md(out_md, 'å•æœºæŠ¥å‘Šå¯¹æ¯”', meta, items)
            print(out_json); print(out_md); return
        else:
            raise SystemExit('ç›®å½•å¯¹æ¯”å¤±è´¥ï¼šè¯·æä¾› centralized/<stamp>/ï¼ˆå« aggregate.jsonï¼‰æˆ– reports/<stamp>/ï¼ˆå« report.json æˆ– storage_performance_report_*.mdï¼‰')

    # å…¼å®¹æ—§å‚æ•°ï¼šcentralized/raw æ¨¡å¼
    if args.source == 'centralized':
        base_dir = os.path.join('test_data', 'reports', 'centralized')
        if args.auto:
            b, c = auto_pick(base_dir)
        else:
            if not args.baseline or not args.current:
                raise SystemExit('éœ€è¦æä¾› --baseline ä¸ --current æˆ–ä½¿ç”¨ --auto')
            b, c = args.baseline, args.current
        a_path = os.path.join(base_dir, b, 'aggregate.json')
        b_path = os.path.join(base_dir, c, 'aggregate.json')
        A = load(a_path); B = load(b_path)
        pa = A.get('meta', {}).get('p'); pb = B.get('meta', {}).get('p')
        va = A.get('meta', {}).get('vm_count'); vb = B.get('meta', {}).get('vm_count')
        if pa != pb or va != vb:
            raise SystemExit(f'ä¸æ”¯æŒä¸åŒç±»å‹çš„å¯¹æ¯”: p={pa} vs {pb}, vm_count={va} vs {vb}')
        items = compare_cases(A, B)
        out_dir = os.path.join('test_data', 'reports', 'compare')
        os.makedirs(out_dir, exist_ok=True)
        out_json = os.path.join(out_dir, f'{b}_vs_{c}.json')
        with open(out_json, 'w', encoding='utf-8') as f:
            json.dump({'baseline': b, 'current': c, 'p': pa, 'vm_count': va, 'items': items}, f, ensure_ascii=False, indent=2)
        out_md = os.path.join(out_dir, f'{b}_vs_{c}.md')
        meta = {'ç±»å‹': 'é›†ä¸­èšåˆ(3pNv)', 'p': pa, 'vm_count': va, 'baseline': b, 'current': c}
        write_md(out_md, 'èšåˆæŠ¥å‘Šå¯¹æ¯”', meta, items)
        print(out_json)
        print(out_md)
    elif args.source == 'raw':
        base_dir = os.path.join('test_data', 'reports', 'centralized')
        if not args.host:
            raise SystemExit('raw å¯¹æ¯”éœ€è¦æä¾› --host')
        if not args.baseline or not args.current:
            raise SystemExit('éœ€è¦æä¾› --baseline ä¸ --current')
        b, c = args.baseline, args.current
        a_path = os.path.join(base_dir, b, 'raw', f'{args.host}.json')
        b_path = os.path.join(base_dir, c, 'raw', f'{args.host}.json')
        if not os.path.isfile(a_path) or not os.path.isfile(b_path):
            raise SystemExit('æœªæ‰¾åˆ°æŒ‡å®šä¸»æœºçš„åŸå§‹JSON')
        A = load(a_path); B = load(b_path)
        items = compare_cases({'cases': A.get('cases', [])}, {'cases': B.get('cases', [])})
        out_dir = os.path.join('test_data', 'reports', 'compare')
        os.makedirs(out_dir, exist_ok=True)
        out_json = os.path.join(out_dir, f'{b}_vs_{c}_{args.host}.json')
        with open(out_json, 'w', encoding='utf-8') as f:
            json.dump({'baseline': b, 'current': c, 'host': args.host, 'items': items}, f, ensure_ascii=False, indent=2)
        out_md = os.path.join(out_dir, f'{b}_vs_{c}_{args.host}.md')
        meta = {'ç±»å‹': 'å•æœº(raw)', 'host': args.host, 'baseline': b, 'current': c}
        write_md(out_md, 'å•æœºæŠ¥å‘Šå¯¹æ¯”', meta, items)
        print(out_json)
        print(out_md)
    else:
        raise SystemExit('è¯·ä½¿ç”¨ --dirA/--dirB æŒ‡å®šä¸¤ä¸ªæ–‡ä»¶å¤¹ï¼Œæˆ– --source centralized/raw æ—§æ¨¡å¼')


if __name__ == '__main__':
    main()
def _to_float(s: str) -> float:
    try:
        return float(s.strip())
    except Exception:
        return 0.0


def parse_md_cases(md_path: str) -> dict:
    if not os.path.isfile(md_path):
        return {'cases': []}
    with open(md_path, 'r', encoding='utf-8', errors='ignore') as f:
        lines = f.read().splitlines()
    cases = []
    header_idx = -1
    for i, l in enumerate(lines):
        if l.strip().startswith('|') and ('åç§°' in l or 'è¯»å†™æ¨¡å¼' in l):
            header_idx = i
            break
    if header_idx == -1:
        return {'cases': []}
    # build column index map
    header_cells = [c.strip() for c in lines[header_idx].split('|')]
    col_map = {name: idx for idx, name in enumerate(header_cells) if name}
    sep_idx = header_idx + 1
    for j in range(sep_idx + 1, len(lines)):
        row = lines[j].strip()
        if not row.startswith('|'):
            break
        cells = [c.strip() for c in row.split('|')]
        if len(cells) < len(header_cells):
            continue
        if 'åç§°' in col_map:
            name = cells[col_map['åç§°']]
            riops = _to_float(cells[col_map.get('è¯»IOPS','') or 0])
            wiops = _to_float(cells[col_map.get('å†™IOPS','') or 0])
            rmbps = _to_float(cells[col_map.get('è¯»MB/s','') or 0])
            wmbps = _to_float(cells[col_map.get('å†™MB/s','') or 0])
            rlat = _to_float(cells[col_map.get('è¯»å»¶è¿Ÿ(Î¼s)','') or 0])
            wlat = _to_float(cells[col_map.get('å†™å»¶è¿Ÿ(Î¼s)','') or 0])
        else:
            # è¯¦ç»†æŠ¥å‘Š
            mode = cells[col_map.get('è¯»å†™æ¨¡å¼', 0)]
            qd = cells[col_map.get('é˜Ÿåˆ—æ·±åº¦', 0)]
            nj = cells[col_map.get('å¹¶å‘æ•°', 0)]
            name = f"{mode} QD{qd} J{nj}"
            riops = _to_float(cells[col_map.get('è¯»å–IOPS','') or 0])
            wiops = _to_float(cells[col_map.get('å†™å…¥IOPS','') or 0])
            rmbps = _to_float(cells[col_map.get('è¯»å–å¸¦å®½(MB/s)','') or 0])
            wmbps = _to_float(cells[col_map.get('å†™å…¥å¸¦å®½(MB/s)','') or 0])
            rlat = _to_float(cells[col_map.get('è¯»å–å»¶è¿Ÿ(Î¼s)','') or 0])
            wlat = _to_float(cells[col_map.get('å†™å…¥å»¶è¿Ÿ(Î¼s)','') or 0])
        cases.append({
            'name': name,
            'read': {'iops': riops, 'bw_MBps': rmbps, 'lat_us': rlat},
            'write': {'iops': wiops, 'bw_MBps': wmbps, 'lat_us': wlat},
        })
    return {'cases': cases}
